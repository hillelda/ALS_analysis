{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hillelda/ALS_analysis/blob/main/ex1/ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "ViXcSiABL3A9",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.760023Z",
          "start_time": "2024-05-22T08:05:28.370526Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# for clab\n",
        "!git clone https://github.com/avrymi-asraf/IDL-huji.git\n",
        "!mv /content/IDL-huji/ex1/ex1_data* ."
      ],
      "metadata": {
        "id": "NSb7IqrvNSL6",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.779557Z",
          "start_time": "2024-05-22T08:05:30.761680Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# make data into 180 vector\n",
        "def load_raw(folder_path ='C:\\\\Users\\H\\PycharmProjects\\IDL-huji\\ex1\\ex1_data\\\\'):\n",
        "    raw_neg_data = open(folder_path+'neg_A0201.txt', 'r').read().split('\\n')\n",
        "    raw_pos_data = open(folder_path+'pos_A0201.txt', 'r').read().split('\\n')\n",
        "    return raw_neg_data, raw_pos_data\n",
        "# raw_neg_data , raw_pos_data = load_raw()\n",
        "raw_neg_data , raw_pos_data = load_raw('ex1_data/')\n",
        "\n",
        "amino_to_ind = {i:c for c,i in enumerate(set(\"\".join(raw_neg_data)))}\n"
      ],
      "metadata": {
        "id": "EWRJbOscRCsd",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.795188Z",
          "start_time": "2024-05-22T08:05:30.779557Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Kn0BdGWO7mhO",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.810191Z",
          "start_time": "2024-05-22T08:05:30.795188Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def peptide2vec(peptides):\n",
        "    t = torch.zeros(len(peptides),len(amino_to_ind) * len(peptides[0]))\n",
        "    for j,peptide in enumerate(peptides):\n",
        "        for i,amino in enumerate(peptide):\n",
        "            t[j, i*len(amino_to_ind) +amino_to_ind[amino]] = 1\n",
        "    return t"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "z_kvFe277mhO",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.825890Z",
          "start_time": "2024-05-22T08:05:30.811676Z"
        }
      },
      "cell_type": "code",
      "source": [
        "#print(peptide2vec(load_raw()[1]))\n",
        "# t = peptide2vec(load_raw()[0][:10])\n",
        "# px.imshow(t)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ycMc9anC7mhO",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.844428Z",
          "start_time": "2024-05-22T08:05:30.827888Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def load_vec_data(raw_neg_data , raw_pos_data):\n",
        "    neg_data = peptide2vec(raw_neg_data)\n",
        "    pos_data = peptide2vec(raw_pos_data)\n",
        "    return neg_data, pos_data\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "svIllr187mhO",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.874957Z",
          "start_time": "2024-05-22T08:05:30.844428Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def split_train_test(neg_data, pos_data,ratio=0.9):\n",
        "    shuffle_pos = torch.randperm(len(pos_data))\n",
        "    num_train_pos = int(ratio*len(pos_data))\n",
        "    idx_train_pos = shuffle_pos[num_train_pos:]\n",
        "    idx_test_pos = shuffle_pos[:num_train_pos]\n",
        "\n",
        "    shuffle_neg = torch.randperm(len(neg_data))\n",
        "    num_train_neg = int(ratio*len(neg_data))\n",
        "    idx_train_neg = shuffle_neg[num_train_neg:]\n",
        "    idx_test_neg = shuffle_neg[:num_train_neg]\n",
        "\n",
        "    return pos_data[idx_train_pos],pos_data[idx_test_pos], neg_data[idx_train_neg], neg_data[idx_test_neg]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "iYYIYFO97mhP",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.890763Z",
          "start_time": "2024-05-22T08:05:30.876955Z"
        }
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "\n",
        "def make_data_set(pos_train, pos_test, neg_train, neg_test):\n",
        "    train_data = torch.cat((pos_train, neg_train))\n",
        "    train_labels = torch.cat((torch.ones(len(pos_train)), torch.zeros(len(neg_train))))\n",
        "    train_data_set = TensorDataset(train_data, train_labels)\n",
        "\n",
        "    test_data = torch.cat((pos_test, neg_test))\n",
        "    test_labels = torch.cat((torch.ones(len(pos_test)), torch.zeros(len(neg_test))))\n",
        "\n",
        "    class_count = torch.bincount(train_labels.to(int))\n",
        "    class_weights = 1. / class_count.float()\n",
        "    sample_weights = class_weights[train_labels.to(int)]\n",
        "    train_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "    return train_data_set, train_sampler, test_data, test_labels\n",
        "\n",
        "# todo: use BCEWithLogitsLoss whith pos_weight to balance the classes\n",
        "\n",
        "# todo: another option: use a dataloader, put the pos len(neg/pos) times in the dataset.\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def make_unbiased_data_loader(train_data_set, test_data, test_labels,batch_size=16,sampler=None):\n",
        "    # train_loader = DataLoader(train_data_set, batch_size=batch_size,sampler=sampler)\n",
        "    train_loader = DataLoader(train_data_set, batch_size=batch_size)\n",
        "    return train_loader, test_data, test_labels"
      ],
      "metadata": {
        "id": "ZOvr4zi0Aznw",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.911031Z",
          "start_time": "2024-05-22T08:05:30.892377Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Hzbx0z-p7mhP",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.926654Z",
          "start_time": "2024-05-22T08:05:30.911031Z"
        }
      },
      "cell_type": "code",
      "source": [
        "class MLP_multi_perceptron(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLP_multi_perceptron, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc_hidden = tourch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc_hidden(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        # out = self.sigmoid(out) todo: loss function is BCEWithLogits\n",
        "        return out\n",
        "    def predict(self,x,threshold=0.5):\n",
        "        # return (self.forward(x)>threshold).to(float) todo: loss function is BCE\n",
        "        return (self.sigmoid(self.forward(x))>threshold).to(float)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "9J7XkuQK7mhP",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.942280Z",
          "start_time": "2024-05-22T08:05:30.926654Z"
        }
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_data, test_labels, loss_fn, optimizer, epochs,device):\n",
        "    test_data, test_labels = test_data.to(device), test_labels.to(device)\n",
        "    records = pd.DataFrame(columns=['epoch', 'train_loss', 'test_loss'],index=range(epochs))\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_epoch_loss = 0\n",
        "        for i, (x, y) in enumerate(train_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            cur_loss = loss_fn(model(x).flatten(), y)\n",
        "            train_epoch_loss += cur_loss.item()\n",
        "            cur_loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            # prod = model.predict(test_data.to(device),threshold=0.99)\n",
        "            prod = model.predict(test_data.to(device))\n",
        "            accuracy = torch.mean((prod == test_labels).to(float)).item()\n",
        "            false_pos = torch.mean(((prod == 1) & (test_labels == 0)).to(float)).item()\n",
        "            true_pos = torch.mean(((prod == 1) & (test_labels == 1)).to(float)).item()\n",
        "            false_neg = torch.mean(((prod == 0) & (test_labels == 1)).to(float)).item()\n",
        "            true_neg = torch.mean(((prod == 0) & (test_labels == 0)).to(float)).item()\n",
        "            print(f'false positive: {false_pos*100:.2f},true positive: {true_pos*100:.2f},false negative: {false_neg*100:.2f}, true negative{true_neg*100:.2f}')\n",
        "            print(f'epoch:{epoch} - accuracy: {accuracy*100:.2f}%, Precision: {(true_pos/(true_pos + false_pos + 1e-15))*100:.5f}:%, Recall {(true_pos/max(true_pos+false_neg,1e-10))*100:.2f}%')\n",
        "            # print(f'epoch:{epoch} - accuracy: {accuracy*100:.2f}%, false positive: {false_pos*100:.2f}:%, false negative {false_neg*100:.2f}%')\n",
        "            test_loss = loss_fn(model(test_data).flatten(), test_labels).item()\n",
        "        records.iloc[epoch] = [epoch, train_epoch_loss, test_loss*100]\n",
        "    return  records"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Jp18oa0Q7mhP",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:30.959801Z",
          "start_time": "2024-05-22T08:05:30.944789Z"
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.01\n",
        "HIDDEN_SIZE = 7\n",
        "INPUT_SIZE = len(amino_to_ind) * 9\n",
        "OUTPUT_SIZE = 1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "raw_neg_data, raw_pos_data = load_raw('ex1_data/')\n",
        "# raw_neg_data, raw_pos_data = load_raw()\n",
        "neg_data, pos_data = load_vec_data(raw_neg_data, raw_pos_data)\n",
        "pos_train, pos_test, neg_train, neg_test = split_train_test(neg_data, pos_data)\n",
        "train_data_set, sampler, test_data, test_labels = make_data_set(pos_train, pos_test, neg_train, neg_test)\n",
        "train_loader, test_data, test_labels = make_unbiased_data_loader(train_data_set, test_data, test_labels,BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ufGBWSCiDpc4",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:32.062338Z",
          "start_time": "2024-05-22T08:05:30.961799Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "4oOX3BfL7mhP",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:05:33.543044Z",
          "start_time": "2024-05-22T08:05:32.062338Z"
        }
      },
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = MLP_multi_perceptron(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(DEVICE)\n",
        "# loss_fn = torch.nn.BCELoss()\n",
        "MULTR = 1\n",
        "LOSS_WHIGHT = torch.tensor([MULTR* len(neg_train)/len(pos_train)]).to(DEVICE)\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=LOSS_WHIGHT)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "o7igfN657mhP",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:08:21.328807Z",
          "start_time": "2024-05-22T08:05:33.543044Z"
        }
      },
      "cell_type": "code",
      "source": [
        "record_data = train_model(model,train_loader,test_data,test_labels,loss_fn,optimizer,EPOCHS,DEVICE)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "4FbUICNP7mhQ"
      },
      "cell_type": "code",
      "source": [
        "px.line(record_data,x='epoch',y=['train_loss','test_loss'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hyper parameters\n",
        "1. batch: 32, epochs: ->âˆž , hidden: 25, score: 80"
      ],
      "metadata": {
        "id": "tFaC5v0nIg3J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMNMIrMyZL6s",
        "ExecuteTime": {
          "end_time": "2024-05-22T08:08:21.330843Z",
          "start_time": "2024-05-22T08:08:21.330843Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "JPPj0Nwp7mhQ"
      },
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Sample data (replace with your actual model output and labels)\n",
        "pred = model(test_data.to('cuda')).detach().cpu().numpy()\n",
        "true_labels = test_labels.detach().cpu().numpy()\n",
        "# Calculate ROC curve data\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, pred)\n",
        "roc_auc = auc(fpr, tpr)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the Plotly figure\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=fpr, y=tpr,\n",
        "                         mode='lines',\n",
        "                         line=dict(color='darkorange', width=2),\n",
        "                         name=f'ROC curve (area = {roc_auc:.2f})'))\n",
        "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1],\n",
        "                         mode='lines',\n",
        "                         line=dict(color='navy', width=2, dash='dash'),\n",
        "                         showlegend=False))\n",
        "fig.update_layout(\n",
        "    title='Receiver Operating Characteristic (ROC) Curve',\n",
        "    xaxis_title='False Positive Rate',\n",
        "    yaxis_title='True Positive Rate',\n",
        "    xaxis=dict(range=[0, 1]),\n",
        "    yaxis=dict(range=[0, 1.05]),\n",
        "    width=800,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "yHl8Jq5jX_LY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hqjVo1aiZsCZ"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}